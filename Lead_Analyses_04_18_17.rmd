---
title: "Lead Project Analyses"
author: "Amanda D. Perez-Ceballos & Charles Xie"
date: "April 18, 2017"
output: word_document
---

#  Lead Project Analyses

```{r setup, echo = FALSE, message = FALSE, warning = FALSE }
#Read in libraries.
library(psych)
library(tidyverse)
library(car)
library(dplyr)
library(dplyr)
library(lubridate)
#lme4 and nlme both fit mixed-effects models.
if(!"lme4" %in% installed.packages()) install.packages("lme4")
library(lme4)
#geepack and gee both fit generalized estimating equations.
if(!"geepack" %in% installed.packages()) install.packages("geepack")
library(geepack)
if(!"gee" %in% installed.packages()) install.packages("gee")
library(gee)
#lmerTest adds p-values to lme4 summaries, using Satterthwaite approximation.
if(!"lmerTest" %in% installed.packages()) install.packages("lmerTest")
library(lmerTest)
if(!"gvlma" %in% installed.packages()) install.packages("gvlma")
library(gvlma)
library(ggplot2)
```

## Setting Working Directory and Loading in Data
```{r data, message = FALSE}
#setwd("/Users/JordanLeitner/Google Drive/Berkeley/geo health/water qual/Shared R Workspace")

setwd("C:/Users/amand/Dropbox/Lead GDrive/Shared R Workspace/Complete Lead Dataset")

publicwatersystem <- read.csv("countylist.csv")

publicwaterviolation <- read.csv("violationlist.csv")

publicwaterviolation <- subset(publicwaterviolation, publicwaterviolation$Type == "Violations Present")

#See how many duplicate hash
dupes.lead <- duplicated(publicwaterviolation$HASH) #3,358 duplicate hashes

publicwaterviolation <- publicwaterviolation[!dupes.lead,] #Getting rid of duplicate hashes

summary(dupes.totalviol <- duplicated(publicwaterviolation$HASH)) #Making sure duplicated hashes are gone (it keeps the first instance)

setwd("C:/Users/amand/Dropbox/Lead GDrive")

populationestimates <- read.csv("ACS_10_5YR_B01003_with_ann.csv")

setwd("C:/Users/amand/Dropbox/Lead GDrive/Shared R Workspace")

implicit <- read.csv("2002-2015 FIPS agg race bias all samp groups.csv")

censusdata <- read.csv("2010 population estimates.csv")

census <- merge(censusdata, populationestimates, by = "FIPS")

census$prop_black <- census$BlackPop/census$total_population

census$prop_white <- census$WhitePop/census$total_population

# Make sure your numbers line up after merger. Check incongruencies
totalviol <- merge(publicwaterviolation, publicwatersystem, by = "PWSID")


```
 

## Cleaning Data and Creating More Variables
```{r cleaning, message = FALSE, warning = FALSE}
#create df of every PWSID-FIPS pair
pairs <- (totalviol %>%
            group_by(PWSID, FIPS.Code) %>%
            dplyr::summarise(n=n()))

length(unique(pairs$PWSID)) # of PWSIDs linked to at least one county, 45813
length(unique(pairs$FIPS.Code)) # of counties that are linked to at least 1 PWSID, 2850

#how many PWSIDs within each FIPS?
PWSIDwithinFIPS <- pairs %>%
  group_by(FIPS.Code) %>%
  dplyr::summarise(n =n()) # n here represents num of PWSIDs within FIPS
mean(PWSIDwithinFIPS$n) #on average, each fips has 16 water systems
range(PWSIDwithinFIPS$n) #But, ranges from 1 to 568 PWSIDs within 1 FIPS

#how many FIPs within each PWSID?
FIPswithinPWSID <- pairs %>%
  group_by(PWSID) %>%
  dplyr::summarise(n =n()) # n here represnts num of FIPS within PWSID. On average, 1, but ranges up to 10. 
mean(FIPswithinPWSID$n) #On average, each PWSID only serves one FIPS
range(FIPswithinPWSID$n) #But, it ranges up to 10. 


#converting dates to R date objects (in order to subtract dates)
totalviol$COMPL_PER_BEGIN_DATE <- dmy(totalviol$COMPL_PER_BEGIN_DATE)
totalviol$COMPL_PER_END_DATE <- dmy(totalviol$COMPL_PER_END_DATE) #111085 don't have end dates
totalviol$COMPL_respTime <- totalviol$COMPL_PER_END_DATE  - totalviol$COMPL_PER_BEGIN_DATE 

#length(totalviol$COMPL_respTime) #Making sure the following lines are all the same length
#length(totalviol$COMPL_PER_END_DATE)
#length(totalviol$COMPL_respTime)


#There is a link between IS_MAJOR_VIOL_IND & IS_HEALTH_BASED_IND. When IS_HEALTH_BASED_IND
# is "Y", IS_MAJOR_VIOL_IND is missing. When IS_HEALTH_BASED_IND. = "N", IS_MAJOR_VIOL_IND varies.
table(totalviol$IS_MAJOR_VIOL_IND == "Y" & totalviol$IS_HEALTH_BASED_IND == "Y" )
#Therefore, we will only look at cases where there is a major health violation


#Selecting only cases that are a major health violation
healths <- totalviol %>%
  filter(IS_HEALTH_BASED_IND == "Y") %>%
  group_by(PWSID) %>%  #one row for every PWSID
  summarise(meanRespTime = mean(COMPL_respTime, na.rm = T),  #create summary vars for each PWSID
            meanPopServed = mean(POPULATION_SERVED_COUNT, na.rm = T),
            n = n(), #total of health based violations
            FIPS.Code = mean(FIPS.Code, na.rm = T))



#sum the codes and check
table(duplicated(publicwatersystem$PWSID))
table(duplicated(publicwaterviolation$PWSID))


#Will create df of every PWSID-FIPS pair again, with the dataset only looking at health violations
pairs2 <- (healths %>%
            group_by(PWSID, FIPS.Code) %>%
            dplyr::summarise(n=n()))

length(unique(pairs2$PWSID)) # of PWSIDs linked to at least one county, 22240
length(unique(pairs$FIPS.Code)) # of counties that are linked to at least 1 PWSID, 2850

#how many PWSIDs within each FIPS?
PWSIDwithinFIPS2 <- pairs2 %>%
  group_by(FIPS.Code) %>%
  dplyr::summarise(n =n()) # n here represents num of PWSIDs within FIPS
mean(PWSIDwithinFIPS2$n) #on average, each fips has 8 water systems
range(PWSIDwithinFIPS2$n) #But, ranges from 1 to 138 PWSIDs within 1 FIPS

#how many FIPs within each PWSID?
FIPswithinPWSID2 <- pairs2 %>%
  group_by(PWSID) %>%
  dplyr::summarise(n =n()) # n here represnts num of FIPS within PWSID. On average, 1, but ranges up to 10. 
mean(FIPswithinPWSID2$n) #On average, each PWSID only serves one FIPS
range(FIPswithinPWSID2$n) #Range is 1 to 1, meaning each PWSID only serves one FIPS 



#Merging health violations with PI data
implicitHealth <- merge(implicit, healths, by.x = "FIPS", by.y = "FIPS.Code")

#class(implicitHealth$FIPS) #make sure FIPS is numeric

#implicitHealth$FIPS <- as.numeric(implicitHealth$FIPS)

#class(implicitHealth$meanRespTime) #need to be numeric

#change meanRespTime to numeric  
implicitHealth$meanRespTime <- as.numeric(implicitHealth$meanRespTime)

#drop PWSIDs where mean pop served is zero (super rural places)
implicitHealth <- implicitHealth %>%
  filter(meanPopServed > 0)

implicitHealth <- merge(implicitHealth, census, by = "FIPS")




```

## Preliminary MLMs
```{r mlm, warning=FALSE, error=FALSE, message=FALSE}
#linear mixed effects analysis
#ideal model
#lmm.Vio.theory<- lmer(log(meanRespTime) ~ rBiasALL_Exp_NoAGw * (SOME RACE DEMOGRAPHIC VAR HERE) + SES GINI, POLITICAL STUFF, ETC. + (1|FIPS), weights = meanPopServed,  data = implicitHealth)
#summary(lmm.Vio.theory)

#implicitHealth <- filter(implicitHealth, nFIPSrBiasWht_NoAGw > 100) #limiting to counties with at least 100 responses
#write.csv(implicitHealth, "implicitHealth.csv") We only needed to create/write this once. From now on, we can just read in the CSV in the below line.

implicitHealth <- read.csv("implicitHealth.csv")

#log transform DV, because meanRespTime was skewed
lmm.Vio.pop<- lmer(log(meanRespTime) ~ rBias_AllPs_D_WhiteGood_noAGw + (1|FIPS), weights = meanPopServed,  data = implicitHealth)
summary(lmm.Vio.pop) #more biased counties ~ longer response time, right direction but not significant

#model weighting by number of PI responses instead
lmm.Vio.pi <- lmer(log(meanRespTime) ~ rBias_AllPs_D_WhiteGood_noAGw + (1|FIPS), weights = implicitHealth$nFIPSrBias_ALL_NoAGw, data = implicitHealth)
summary(lmm.Vio.pi) #right direction, but not significant when weighting by # of PI responses

cor.test( ~ meanPopServed + nFIPSrBias_ALL_NoAGw,
          data = implicitHealth) #very small correlation b/w # of PI responses & mean # population served

lmm.pop <- lmer(log(meanRespTime) ~ rBias_AllPs_D_WhiteGood_noAGw*prop_black + (1|FIPS), weights = meanPopServed, data = implicitHealth)
summary(lmm.pop)

lmm.pop.pi <- lmer(log(meanRespTime) ~ rBias_AllPs_D_WhiteGood_noAGw*prop_black + (1|FIPS), weights = nFIPSrBias_ALL_NoAGw, data = implicitHealth)
summary(lmm.pop.pi)

lmm.explicit.pop <- lmer(log(meanRespTime) ~ rBiasWh_Exp_NoAgw*prop_black + (1|FIPS), weights = meanPopServed, data = implicitHealth)
summary(lmm.explicit.pop) #significant

lmm.explicit.pi <- lmer(log(meanRespTime) ~ rBiasWh_Exp_NoAgw*prop_black + (1|FIPS), weights = nFIPSrBias_ALL_NoAGw, data = implicitHealth)
summary(lmm.explicit.pi) #significant

#Next steps: 1) Look at other DVs 2)Looking only at Whites Non Hispanic PI 3)Creating a function that will create tribble and plot points from lmm summaries 4) Look at other covariates (Gini, ruralism) 5) Do we have info on how long each PWSID has been open? That could impact the # of violations, etc.

```


## Centering variable to look at interaction effect
```{r centering}
#Creating points to plot
implicitHealth$rBiasWhNoH_Exp_NoAGw_C <- implicitHealth$rBiasWhNoH_Exp_NoAGw - mean(implicitHealth$rBiasWhNoH_Exp_NoAGw, na.rm = T)
implicitHealth$rBiasWh_Exp_NoAgw_C <- implicitHealth$rBiasWh_Exp_NoAgw - mean(implicitHealth$rBiasWh_Exp_NoAgw, na.rm = T)

implicitHealth$prop_black_C <- implicitHealth$prop_black - mean(implicitHealth$prop_black, na.rm = T)

implicitHealth$rBiasWh_Exp_NoAgw_Hi <- implicitHealth$rBiasWh_Exp_NoAgw_C - sd(implicitHealth$rBiasWh_Exp_NoAgw_C, na.rm = T)
implicitHealth$rBiasWh_Exp_NoAgw_Lo <- implicitHealth$rBiasWh_Exp_NoAgw_C + sd(implicitHealth$rBiasWh_Exp_NoAgw_C, na.rm = T)
implicitHealth$prop_Black_Hi <- implicitHealth$prop_black_C - sd(implicitHealth$prop_black_C, na.rm = T)
implicitHealth$prop_Black_Lo <- implicitHealth$prop_black_C + sd(implicitHealth$prop_black_C, na.rm = T)
```

## Getting Values to Look at Interaction
```{r intercepts}
#intercept = low explicit, low prop_black
lmm.explo.blacklo <- lmer(log(meanRespTime) ~ rBiasWh_Exp_NoAgw_Lo*prop_Black_Lo + (1|FIPS), weights = meanPopServed, data = implicitHealth)
summary(lmm.explo.blacklo)

#intercept = low explicit, high prop_black
lmm.explo.blackhi <- lmer(log(meanRespTime) ~ rBiasWh_Exp_NoAgw_Lo*prop_Black_Hi + (1|FIPS), weights = meanPopServed, data = implicitHealth)
summary(lmm.explo.blackhi)

#intercept = high explicit, low prop_black
lmm.exphi.blacklo <- lmer(log(meanRespTime) ~ rBiasWh_Exp_NoAgw_Hi*prop_Black_Lo + (1|FIPS), weights = meanPopServed, data = implicitHealth)
summary(lmm.exphi.blacklo)

#intercept = high explicit, high prop_black
lmm.exphi.blackhi <- lmer(log(meanRespTime) ~ rBiasWh_Exp_NoAgw_Hi*prop_Black_Hi + (1|FIPS), weights = meanPopServed, data = implicitHealth)
summary(lmm.exphi.blackhi)

toPlot <- tribble(
  ~bias, ~Pro_Black, ~logMeanResp,
  "low", "low", lmm.explo.blacklo@beta[1],
  "low", "high", lmm.explo.blackhi@beta[1],
  "high", "low", lmm.exphi.blacklo@beta[1],
  "high", "high", lmm.exphi.blackhi@beta[1]
)

ggplot(toPlot, aes(bias, logMeanResp, color = Pro_Black, group = Pro_Black)) + geom_line()
#Are the places with higher implicit bias more rural (population density)? That could be explaining the slower response time in low prop. black areas
```



## Misc Code
```{r misc, eval = FALSE}
#Next Step is to aggregate "lead" to the water system level for variables of interest.
#Variables of interest:
#IS_HEALTH_BASED_IND: Indicates if this is a health based violation.
#IS_MAJOR_VIOL_IND: A code value that indicates the severity of a Monitoring and Reporting (M) violation, major or minor. 
#POPULATION_SERVED_COUNT: Water systems estimate of the number of people served by the system.
#POP_CAT_5_CODE: Will equal 1 or 2; identifies the population category for water systems serving populations less than or greater than 10,000. 1	<=500 & 2	501-3,300
#PUBLIC_NOTIFICATION_TIER: Numeric code for Public Notification Tier for the violation. 1	Immediate Notice, Within 24 Hours | 2	Notice as Soon as Practical, | 3	Annual Notice
#SEVERITY_IND_CNT: A count indicating the severity of certain DBPR and IESWTR violations.
#STATE_MCL: A numeric value that represents the maximum contaminant level which was exceeded that led to the identification of an MCL violation for a public water system.
#VIOL_MEASURE: A numeric value that represents the analytical result of a contaminant that exceeded the Maximum Contaminant Level (MCL) for that contaminant. For


table(lead$POP_CAT_5_CODE)
table(lead$PUBLIC_NOTIFICATION_TIER) #will create 3 variables, a sum per each of the three tiers by pwsid
table(lead$SEVERITY_IND_CNT) #There are some extreme values here, is this normal?
plot(lead$STATE_MCL)
plot(lead$VIOL_MEASURE)


tier.1 <- lead %>% 
  filter(PUBLIC_NOTIFICATION_TIER == 1 ) %>% 
   group_by(PWSID) %>%
  summarise( tier1_sum = sum(PUBLIC_NOTIFICATION_TIER) )

tier.2 <- lead %>% 
  filter(PUBLIC_NOTIFICATION_TIER == 2 ) %>% 
   group_by(PWSID) %>%
  summarise( tier2_sum = sum(PUBLIC_NOTIFICATION_TIER) )

tier.3 <- lead %>% 
  filter(PUBLIC_NOTIFICATION_TIER == 3 ) %>% 
   group_by(PWSID) %>%
  summarise( tier3_sum = sum(PUBLIC_NOTIFICATION_TIER) )

tiers <- tier.1 %>%
  merge(tier.2, by = "PWSID", all = TRUE) %>%
  merge(tier.3, by = "PWSID", all = TRUE)

vio_sum <- lead %>%
  group_by(PWSID) %>%
   summarise(healthvio_sum = sum(IS_HEALTH_BASED_IND))


watersystem_level <- vio_sum %>%
  merge(tiers, by = "PWSID", all = TRUE)

```

